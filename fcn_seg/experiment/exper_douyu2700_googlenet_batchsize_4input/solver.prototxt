train_net: "trainval.prototxt"
test_net: "test.prototxt"
test_iter: 200
test_interval: 999999999
base_lr: 1e-08
display: 20
max_iter: 300000
lr_policy: "step"
gamma: 0.1
momentum: 0.99
weight_decay: 0.0005
stepsize: 10000
snapshot: 10000
test_initialization: false
average_loss: 20
iter_size: 1
snapshot_prefix:"./snapshot/douyu_2700_train_600*376"


## tutorial
#base_lr: 0.01     # begin training at a learning rate of 0.01 = 1e-2

#lr_policy: "step" # learning rate policy: drop the learning rate in "steps"
                  # by a factor of gamma every stepsize iterations

#gamma: 0.1        # drop the learning rate by a factor of 10
                  # (i.e., multiply it by a factor of gamma = 0.1)

#stepsize: 100000  # drop the learning rate every 100K iterations
